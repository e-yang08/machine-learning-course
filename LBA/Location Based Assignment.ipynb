{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f5b90c",
   "metadata": {},
   "source": [
    "# Location Based Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a421fe",
   "metadata": {},
   "source": [
    "### ** Principle Landmarks**\n",
    "- At least 20 photos of your favorite landmark\n",
    "- taken during the day and over a period of at least 4 hours\n",
    "- Something that creates a time-lapse of your favorite landmark would be ideal, but is not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd075f0",
   "metadata": {},
   "source": [
    "### Core assignment: \n",
    "#### write code that does the following:\n",
    "\n",
    "1. Processes all photos down to a size not exceeding 512 pixels in either width or height\n",
    "2. Using principal components analysis (PCA) project your images down to a 2 dimensional representation\n",
    "3. Visually inspect the 2D locations of each photo in the new space\n",
    "4. Show the reconstruction from each low-dimensional representation\n",
    "5. Finally, pick a point that is far away from any known location and plot its reconstruction\n",
    "\n",
    "- If you perform any other image processing steps, please clearly note them in your report. This is meant to be a reasonably light-hearted assignment, so feel free to pick irreverent landmarks or use interesting image processing techniques to find artistic reconstructions. You may also try to conduct this assignment in three dimensions, but no higher!\n",
    "\n",
    "- Hand in a single PDF containing all your results and a short discussion of your findings.\n",
    "\n",
    "#### Make sure to include:\n",
    "\n",
    "at least 10 of your small photos and their associated reconstructions\n",
    "the scatterplot of all images in the 2D space,\n",
    "- and where your new point is the reconstruction from your new point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7deb5e6",
   "metadata": {},
   "source": [
    "Import all relevant frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "740a2272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "from resizeimage import resizeimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c515d85d",
   "metadata": {},
   "source": [
    "### Step 1. \n",
    "Processes all photos down to a size not exceeding 512 pixels in either width or height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7a2e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize and crop images\n",
    "def resize_images(images_path,pixel):\n",
    "    '''\n",
    "    Resizes and crops images using the function given\n",
    "    in the Session 7 repo from load_images.py.\n",
    "    '''    \n",
    "    flattened = []\n",
    "    \n",
    "    # for each image path\n",
    "    for path in images_path:\n",
    "        # open it as a read file in binary mode\n",
    "        with open(path, 'r+b') as f:\n",
    "            #open it as an image\n",
    "            with Image.open(f) as image:\n",
    "                # resize the image to be more manageable\n",
    "                cover = resizeimage.resize_cover(image, [pixel,pixel]) # 250, 250\n",
    "                # flatten the matrix to an array and append it to all flattened images\n",
    "                flattened.append((np.array(cover).flatten(), 0))\n",
    "\n",
    "    # Flatten it once more\n",
    "    flattened = np.asarray(flattened)\n",
    "\n",
    "    # Declare which are the X and Y inputs\n",
    "    X = flattened[:,0]\n",
    "    Y = flattened[:,1]\n",
    "\n",
    "    # Use np.stack to put the data into the right dimension\n",
    "    X = np.stack(i for i in X)\n",
    "    Y = np.stack(i for i in Y)\n",
    "    \n",
    "    # return resized images\n",
    "    return X, Y\n",
    "path_j = glob(\"/Users/ey08/Documents/Minerva/Fall 2022/cs156-pcw-e-yang08/06/Jersey/*\")\n",
    "pixel = 512\n",
    "X,Y = resize_images(path_j,pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78726d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images using function\n",
    "images = X\n",
    "\n",
    "print(f'Total Images: {len(images)}')\n",
    "print(f'Images Shape: {images.shape}')\n",
    "\n",
    "# plot samples of original images\n",
    "fig = plt.figure(figsize=(15, 6)) \n",
    "\n",
    "for i in range(10): \n",
    "    ax = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[]) \n",
    "    img = Image.fromarray(images[i].reshape(100,100,3), 'RGB') \n",
    "    ax.imshow(img, interpolation='nearest') \n",
    "    \n",
    "plt.suptitle('Original Images', y=0.95)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9b4ee7",
   "metadata": {},
   "source": [
    "### Step 2. \n",
    "Using principal components analysis (PCA) project your images down to a 2 dimensional representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1942cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "# apply PCA using all components\n",
    "n_components = len(images) #dimensions\n",
    "pca = decomposition.PCA(n_components=n_components) #decomposes by n_components variables\n",
    "\n",
    "# fit images to PCA to reduce dimensions\n",
    "transformed = pca.fit_transform(images)\n",
    "\n",
    "print(transformed.shape)\n",
    "# plot number of components vs. explained variance\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "components = np.arange(1, n_components+1, step=1)\n",
    "var = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.plot(components, var, color='pink')\n",
    "plt.axhline(y=0.95, color='teal', label='95% Var Explained')\n",
    "\n",
    "plt.title('Number of Components Needed to Explain Variance')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Variance (%)')\n",
    "\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f05f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate PCA results and save image for each dimension\n",
    "\n",
    "samples = []\n",
    "expl_var = []\n",
    "dims = []\n",
    "\n",
    "for i in range(1,len(images)+1,1):\n",
    "    \n",
    "    # apply PCA\n",
    "    pca = decomposition.PCA(n_components=i)\n",
    "\n",
    "    # fit images to PCA to reduce dimensions\n",
    "    transformed = pca.fit_transform(images)\n",
    "    \n",
    "    # transform image to save samples\n",
    "    inverse = pca.inverse_transform(transformed)\n",
    "    formatted = np.clip(inverse, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # save one random sample from each dimension\n",
    "    random_row = np.random.randint(len(images), size=1)\n",
    "    sample = formatted[random_row]\n",
    "    \n",
    "    # calculate explained variance\n",
    "    pca_var_expl = \\\n",
    "    np.round(np.cumsum(pca.explained_variance_ratio_)[-1],2)\n",
    "    \n",
    "    # save results\n",
    "    samples.append(sample)    \n",
    "    expl_var.append(pca_var_expl)\n",
    "    dims.append(i)\n",
    "    \n",
    "# plot sample from each dimension\n",
    "\n",
    "print(\"finished applying PCA\")\n",
    "# reshape formatted samples\n",
    "reshaped = []\n",
    "for i in samples:\n",
    "    new_img = Image.fromarray(i.reshape(100,100,3), 'RGB')\n",
    "    reshaped.append(new_img)\n",
    "\n",
    "# plot samples\n",
    "fig = plt.figure(figsize=(16, 20)) \n",
    "\n",
    "for i in range(len(samples)): \n",
    "    ax = fig.add_subplot(6, 4, i+1, xticks=[], yticks=[]) \n",
    "    ax.imshow(reshaped[i], interpolation='nearest')\n",
    "    ax.set_title(f'Dim: {dims[i]}, Var: {expl_var[i]}')\n",
    "    \n",
    "plt.suptitle('Reconstructed Images (All Dimensions)', y=0.92)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f4ef7",
   "metadata": {},
   "source": [
    "### Discussion of Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45c80d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1718ebef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f49481ec",
   "metadata": {},
   "source": [
    "\n",
    "###  Optional extension:\n",
    "\n",
    "#### Extend your previous code in the following way:\n",
    "- Using the first few PCA components, train a linear regression model to predict the time of day the photos were taken (you can pull the timestamps directly from your phone to get your target feature).\n",
    "- Using the first few PCA components, train any of the classifiers we've used so far in class (using k-fold crossvalidation) to predict whether the photo was taken in the first half of the photos or in the second half of the photos.\n",
    "- Evaluate these models using any of the performance metrics we've discussed in class and produce a visualization of their accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2574c69",
   "metadata": {},
   "source": [
    "- weather\n",
    "- time point\n",
    "- shade\n",
    "- cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7ab07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66cf22b9",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b23bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "# NB\n",
    "# Import Gaussian Naive Bayes model\n",
    "# reference: https://www.datacamp.com/tutorial/naive-bayes-scikit-learn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(accuracy_score(y_test, y_pred))\n",
    "plt.title(all_sample_title, size = 15)\n",
    "\n",
    "print(\"Classifier Report\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7885f45f",
   "metadata": {},
   "source": [
    "### Assignment Information\n",
    "Weight:\n",
    "10%\n",
    "\n",
    "#### Learning Outcomes Added\n",
    "- cs156-MLCode: Produce working, readable, and performant Python implementations of a variety of machine learning systems using appropriate libraries and software tools.\n",
    "\n",
    "- cs156-MLDevelopment: Contribute to the quality of ML resources for current and future students by compiling learning resources, sharing code, creating study groups, and supporting other student's learning.\n",
    "\n",
    "- cs156-MLExplaination: Clearly articulate machine learning systems, algorithms, and techniques using appropriate oral and written descriptions, mathematical notation, and visualizations.\n",
    "\n",
    "- cs156-MLFlexibility: Reason flexibly, apply information in new contexts, produce novel work, and articulate meta-knowledge about machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341655e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00818015",
   "metadata": {},
   "source": [
    "fit PCA\n",
    "--> classify cats/dogs.\n",
    "\n",
    "train on clothes\n",
    "-> classify the different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72078e75",
   "metadata": {},
   "source": [
    "rotating around the landmark --> assume which result\n",
    "run on notebooks locally\n",
    "not necessarily upload the images\n",
    "\n",
    "code comments---audience. professor reads it!\n",
    "steps, procedure within the code cell book\n",
    "\n",
    "#### idea\n",
    "different time points of that small stuff putting cigarette."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37a20db",
   "metadata": {},
   "source": [
    "- point cloud\n",
    "- 3D -- depth and lighting\n",
    "- iOS14\n",
    "- Use cases: predict the price of NFT ---> collect data from online?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a31806b",
   "metadata": {},
   "source": [
    "#### DRAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9184727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-resize-image # install new python resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6487018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "reference https://sle-collaboration.minervaproject.com/?id=6e1e4824-ce66-4824-8536-\n",
    "aa32dd64ad24&userId=10914&name=Erela+Yang&avatar=https%3A//s3.amazonaws.com/picasso.\n",
    "fixtures/Youqi_Yang_10914_2021-02-21T10%3A15%3A28.132Z&isInstructor=0&signature=4a0e\n",
    "398d189bc7552fbd57bfd85393c51aa63a25d9b9aa364468b2b2856acc87\n",
    "\n",
    "\"\"\"\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from resizeimage import resizeimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# resize and crop images\n",
    "def resize_images(images_path):\n",
    "    '''\n",
    "    Resizes and crops images using the function given\n",
    "    in the Session 7 repo from load_images.py.\n",
    "    '''    \n",
    "    flattened = []\n",
    "    \n",
    "    # for each image path\n",
    "    for path in images_path:\n",
    "        # open it as a read file in binary mode\n",
    "        with open(path, 'r+b') as f:\n",
    "            #open it as an image\n",
    "            with Image.open(f) as image:\n",
    "                # resize the image to be more manageable\n",
    "                cover = resizeimage.resize_cover(image, [100,100]) # 250, 250\n",
    "                # flatten the matrix to an array and append it to all flattened images\n",
    "                flattened.append((np.array(cover).flatten(), 0))\n",
    "\n",
    "    # Flatten it once more\n",
    "    flattened = np.asarray(flattened)\n",
    "\n",
    "    # Declare which are the X and Y inputs\n",
    "    X = flattened[:,0]\n",
    "    Y = flattened[:,1]\n",
    "\n",
    "    # Use np.stack to put the data into the right dimension\n",
    "    X = np.stack(i for i in X)\n",
    "    Y = np.stack(i for i in Y)\n",
    "    \n",
    "    # return resized images\n",
    "    return X, Y\n",
    "path_j = glob(\"/Users/ey08/Documents/Minerva/Fall 2022/cs156-pcw-e-yang08/06/Jersey/*\")\n",
    "X,Y = resize_images(path_j)\n",
    "# images = resize_images(file)[0]\n",
    "# path_s = \"/Users/ey08/Documents/Minerva/Fall 2022/cs156-pcw-e-yang08/06/Shirt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678af24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images using function\n",
    "images = X\n",
    "\n",
    "print(f'Total Images: {len(images)}')\n",
    "print(f'Images Shape: {images.shape}')\n",
    "\n",
    "# plot samples of original images\n",
    "fig = plt.figure(figsize=(15, 6)) \n",
    "\n",
    "for i in range(10): \n",
    "    ax = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[]) \n",
    "    img = Image.fromarray(images[i].reshape(100,100,3), 'RGB') \n",
    "    ax.imshow(img, interpolation='nearest') \n",
    "    \n",
    "plt.suptitle('Original Images', y=0.95)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922aa9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "# apply PCA using all components\n",
    "n_components = len(images) #dimensions\n",
    "pca = decomposition.PCA(n_components=n_components) #decomposes by n_components variables\n",
    "\n",
    "# fit images to PCA to reduce dimensions\n",
    "transformed = pca.fit_transform(images)\n",
    "\n",
    "print(transformed.shape)\n",
    "# plot number of components vs. explained variance\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "components = np.arange(1, n_components+1, step=1)\n",
    "var = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.plot(components, var, color='pink')\n",
    "plt.axhline(y=0.95, color='teal', label='95% Var Explained')\n",
    "\n",
    "plt.title('Number of Components Needed to Explain Variance')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Variance (%)')\n",
    "\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d46ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate PCA results and save image for each dimension\n",
    "\n",
    "samples = []\n",
    "expl_var = []\n",
    "dims = []\n",
    "\n",
    "for i in range(1,len(images)+1,1):\n",
    "    \n",
    "    # apply PCA\n",
    "    pca = decomposition.PCA(n_components=i)\n",
    "\n",
    "    # fit images to PCA to reduce dimensions\n",
    "    transformed = pca.fit_transform(images)\n",
    "    \n",
    "    # transform image to save samples\n",
    "    inverse = pca.inverse_transform(transformed)\n",
    "    formatted = np.clip(inverse, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # save one random sample from each dimension\n",
    "    random_row = np.random.randint(len(images), size=1)\n",
    "    sample = formatted[random_row]\n",
    "    \n",
    "    # calculate explained variance\n",
    "    pca_var_expl = \\\n",
    "    np.round(np.cumsum(pca.explained_variance_ratio_)[-1],2)\n",
    "    \n",
    "    # save results\n",
    "    samples.append(sample)    \n",
    "    expl_var.append(pca_var_expl)\n",
    "    dims.append(i)\n",
    "    \n",
    "# plot sample from each dimension\n",
    "\n",
    "print(\"finished applying PCA\")\n",
    "# reshape formatted samples\n",
    "reshaped = []\n",
    "for i in samples:\n",
    "    new_img = Image.fromarray(i.reshape(100,100,3), 'RGB')\n",
    "    reshaped.append(new_img)\n",
    "\n",
    "# plot samples\n",
    "fig = plt.figure(figsize=(16, 20)) \n",
    "\n",
    "for i in range(len(samples)): \n",
    "    ax = fig.add_subplot(6, 4, i+1, xticks=[], yticks=[]) \n",
    "    ax.imshow(reshaped[i], interpolation='nearest')\n",
    "    ax.set_title(f'Dim: {dims[i]}, Var: {expl_var[i]}')\n",
    "    \n",
    "plt.suptitle('Reconstructed Images (All Dimensions)', y=0.92)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4231bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
